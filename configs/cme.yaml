base:
  data_path: null
  save_path: None # for save model in training
  log_path: checkpoints
  device: cuda
  random_seed: 1

data:
  name: 'lasc2'
  single: true
  crop: true
  num_classes: 1 # number of classes
  input_size: 512
  mean: [0.425753653049469, 0.29737451672554016, 0.21293757855892181] # 'auto' or a list of three numbers for RGB
  std: [0.27670302987098694, 0.20240527391433716, 0.1686241775751114] # 'auto' or a list of three numbers for RGB
  sampling_strategy: instance_balanced # instance_balanced / class_balanced / progressively_balanced. ref: https://arxiv.org/abs/1910.09217
  sampling_weights_decay_rate: 0.9 # if sampling_strategy is progressively_balanced, sampling weight will change from class_balanced to instance_balanced
  data_augmentation: [] # available operations are list in 'data_augmentation_args' below
#    - random_crop
#    - horizontal_flip
#    - vertical_flip
#    - color_distortion
#    - rotation

model:
  dual: False
  backbone: "VGG16" #
  pretrained: True
  stem_out_channels: 64
  trans_func: "BottleneckWithFixedBatchNorm"
  freeze_stage: -1
  vgg_backbone_out_channels: 512
  resnet_backbone_out_channels: 1024 # C4:1024 C5:2048 ; FPN: C4: 256
  width_per_group: 8
  num_groups: 32
  res2out_channels: 256
  init_feature_channels: 512
  filter_num: 6
  # filter_dimension: 256
  feature_map_dim: 32
  attention_head_num: 8
  add_attention: False

train:
  freeze: True
  network: resnet18 # available networks are list in networks.yaml
  pretrained: True # load weights from pre-trained model training on ImageNet
  finetune: False # 
  checkpoint: False # for load pre-trained model for image
  dual_checkpoint: False # for load pre-trained model for parameter
  epochs: 100
  batch_size: 4
  num_workers: 8 # number of cpus used to load data at each step
  criterion: L2 #  mean_square_error # available criterions are list in 'criterion_args' below
  loss_weight: null # null / balance / dynamic / list with shape num_classes. Weights for loss function. Don't use it with weighted sampling!
  loss_weight_decay_rate: 0 # if loss_weights is dynamic, loss weight will decay from balance to equivalent weights
  warmup_epochs: 5 # set to 0 to disable warmup
  kappa_prior: true # save model with higher kappa or higher accuracy in validation set
  save_interval: 100 # the epoch interval of saving model
  eval_interval: 1 # the epoch interval of evaluating model on val dataset
  sample_view: false # save and visualize a batch of images on Tensorboard
  sample_view_interval: 100 # the steps interval of saving samples on Tensorboard. Note that frequently saving images will slow down the training speed.
  pin_memory: false # enables fast data transfer to CUDA-enabled GPUs

solver:
  optimizer: SGD # SGD / ADAM / ADAMW
  learning_rate: 0.001 # initial learning rate
  lr_scheduler: false # clipped_cosine # available schedulers are list in 'scheduler_args' below. please remember to update scheduler_args when number of epoch changes.
  momentum: 0.6 # only for SGD. set to 0 to disable momentum
  nesterov: true # only for SGD.
  weight_decay: 0.0005 # set to 0 to disable weight decay

criterion_args:
  cross_entropy: {}
  L1: {}
  L2: {}
  smooth_L1: {}
  kappa_loss: {}
  focal_loss:
    alpha: 5
    reduction: mean
  arc_smooth_L1:
    beta: 12

# please refer to documents of torch.optim
scheduler_args:
  exponential:
    gamma: 0.99 # multiplicative factor of learning rate decay
  multiple_steps:
    milestones: [50, 100, 150]
    gamma: 0.5 # multiplicative factor of learning rate decay
  cosine:
    T_max: 50 # maximum number of iterations
    eta_min: 0 # minimum learning rate
  reduce_on_plateau:
    mode: min
    factor: 0.1 # new learning rate = factor * learning rate
    patience: 5 # number of epochs with no improvement after which learning rate will be reduced.
    threshold: 0.0001 # threshold for measuring the new optimum
    eps: 0.00001 # minimal decay applied to learning rate
  clipped_cosine:
    T_max: 25
    min_lr: 0.0001

data_augmentation_args:
  horizontal_flip:
    prob: 0.5
  vertical_flip:
    prob: 0.5
  color_distortion:
    prob: 1.0
    brightness: 0.2
    contrast: 0.2
    saturation: 0.1
    hue: 0.1
  random_crop: # randomly crop and resize to input_size
    prob: 1.0
    scale: [0.87, 1.15] # range of size of the origin size cropped
    ratio: [0.7, 1.3] # range of aspect ratio of the origin aspect ratio cropped
  rotation:
    prob: 1.0
    degrees: [-180, 180]
  translation:
    prob: 1
    range: [0.2, 0.2]
  grayscale: # randomly convert image to grayscale
    prob: 0.5
  gaussian_blur: # only available for torch version >= 1.7.1.
    prob: 0.2
    kernel_size: 7
    sigma: 0.5
  value_fill: 127 # NOT a data augmentation operation. pixel fill value for the area outside the image
